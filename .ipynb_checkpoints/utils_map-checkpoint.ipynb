{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd63a88-5835-4685-bc3b-a288ec58786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import math\n",
    "import operator\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "try:\n",
    "    from pycocotools.coco import COCO\n",
    "    from pycocotools.cocoeval import COCOeval\n",
    "except:\n",
    "    pass\n",
    "import cv2\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "    0,0 ------> x (width)\n",
    "     |\n",
    "     |  (Left,Top)\n",
    "     |      *_________\n",
    "     |      |         |\n",
    "            |         |\n",
    "     y      |_________|\n",
    "  (height)            *\n",
    "                (Right,Bottom)\n",
    "'''\n",
    "\n",
    "def log_average_miss_rate(precision, fp_cumsum, num_images):\n",
    "    \"\"\"\n",
    "        log-average miss rate:\n",
    "            Calculated by averaging miss rates at 9 evenly spaced FPPI points\n",
    "            between 10e-2 and 10e0, in log-space.\n",
    "\n",
    "        output:\n",
    "                lamr | log-average miss rate\n",
    "                mr | miss rate\n",
    "                fppi | false positives per image\n",
    "\n",
    "        references:\n",
    "            [1] Dollar, Piotr, et al. \"Pedestrian Detection: An Evaluation of the\n",
    "               State of the Art.\" Pattern Analysis and Machine Intelligence, IEEE\n",
    "               Transactions on 34.4 (2012): 743 - 761.\n",
    "    \"\"\"\n",
    "\n",
    "    if precision.size == 0:\n",
    "        lamr = 0\n",
    "        mr = 1\n",
    "        fppi = 0\n",
    "        return lamr, mr, fppi\n",
    "\n",
    "    fppi = fp_cumsum / float(num_images)\n",
    "    mr = (1 - precision)\n",
    "\n",
    "    fppi_tmp = np.insert(fppi, 0, -1.0)\n",
    "    mr_tmp = np.insert(mr, 0, 1.0)\n",
    "\n",
    "    ref = np.logspace(-2.0, 0.0, num = 9)\n",
    "    for i, ref_i in enumerate(ref):\n",
    "        j = np.where(fppi_tmp <= ref_i)[-1][-1]\n",
    "        ref[i] = mr_tmp[j]\n",
    "\n",
    "    lamr = math.exp(np.mean(np.log(np.maximum(1e-10, ref))))\n",
    "\n",
    "    return lamr, mr, fppi\n",
    "\n",
    "\"\"\"\n",
    " throw error and exit\n",
    "\"\"\"\n",
    "def error(msg):\n",
    "    print(msg)\n",
    "    sys.exit(0)\n",
    "\n",
    "\"\"\"\n",
    " check if the number is a float between 0.0 and 1.0\n",
    "\"\"\"\n",
    "def is_float_between_0_and_1(value):\n",
    "    try:\n",
    "        val = float(value)\n",
    "        if val > 0.0 and val < 1.0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\"\"\"\n",
    " Calculate the AP given the recall and precision array\n",
    "    1st) We compute a version of the measured precision/recall curve with\n",
    "         precision monotonically decreasing\n",
    "    2nd) We compute the AP as the area under this curve by numerical integration.\n",
    "\"\"\"\n",
    "def voc_ap(rec, prec):\n",
    "    \"\"\"\n",
    "    --- Official matlab code VOC2012---\n",
    "    mrec=[0 ; rec ; 1];\n",
    "    mpre=[0 ; prec ; 0];\n",
    "    for i=numel(mpre)-1:-1:1\n",
    "            mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    end\n",
    "    i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    rec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    rec.append(1.0) # insert 1.0 at end of list\n",
    "    mrec = rec[:]\n",
    "    prec.insert(0, 0.0) # insert 0.0 at begining of list\n",
    "    prec.append(0.0) # insert 0.0 at end of list\n",
    "    mpre = prec[:]\n",
    "    \"\"\"\n",
    "     This part makes the precision monotonically decreasing\n",
    "        (goes from the end to the beginning)\n",
    "        matlab: for i=numel(mpre)-1:-1:1\n",
    "                    mpre(i)=max(mpre(i),mpre(i+1));\n",
    "    \"\"\"\n",
    "    for i in range(len(mpre)-2, -1, -1):\n",
    "        mpre[i] = max(mpre[i], mpre[i+1])\n",
    "    \"\"\"\n",
    "     This part creates a list of indexes where the recall changes\n",
    "        matlab: i=find(mrec(2:end)~=mrec(1:end-1))+1;\n",
    "    \"\"\"\n",
    "    i_list = []\n",
    "    for i in range(1, len(mrec)):\n",
    "        if mrec[i] != mrec[i-1]:\n",
    "            i_list.append(i) # if it was matlab would be i + 1\n",
    "    \"\"\"\n",
    "     The Average Precision (AP) is the area under the curve\n",
    "        (numerical integration)\n",
    "        matlab: ap=sum((mrec(i)-mrec(i-1)).*mpre(i));\n",
    "    \"\"\"\n",
    "    ap = 0.0\n",
    "    for i in i_list:\n",
    "        ap += ((mrec[i]-mrec[i-1])*mpre[i])\n",
    "    return ap, mrec, mpre\n",
    "\n",
    "\n",
    "\"\"\"\n",
    " Convert the lines of a file to a list\n",
    "\"\"\"\n",
    "def file_lines_to_list(path):\n",
    "    # open txt file lines to a list\n",
    "    with open(path) as f:\n",
    "        content = f.readlines()\n",
    "    # remove whitespace characters like `\\n` at the end of each line\n",
    "    content = [x.strip() for x in content]\n",
    "    return content\n",
    "\n",
    "\"\"\"\n",
    " Draws text in image\n",
    "\"\"\"\n",
    "def draw_text_in_image(img, text, pos, color, line_width):\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    fontScale = 1\n",
    "    lineType = 1\n",
    "    bottomLeftCornerOfText = pos\n",
    "    cv2.putText(img, text,\n",
    "            bottomLeftCornerOfText,\n",
    "            font,\n",
    "            fontScale,\n",
    "            color,\n",
    "            lineType)\n",
    "    text_width, _ = cv2.getTextSize(text, font, fontScale, lineType)[0]\n",
    "    return img, (line_width + text_width)\n",
    "\n",
    "\"\"\"\n",
    " Plot - adjust axes\n",
    "\"\"\"\n",
    "def adjust_axes(r, t, fig, axes):\n",
    "    # get text width for re-scaling\n",
    "    bb = t.get_window_extent(renderer=r)\n",
    "    text_width_inches = bb.width / fig.dpi\n",
    "    # get axis width in inches\n",
    "    current_fig_width = fig.get_figwidth()\n",
    "    new_fig_width = current_fig_width + text_width_inches\n",
    "    propotion = new_fig_width / current_fig_width\n",
    "    # get axis limit\n",
    "    x_lim = axes.get_xlim()\n",
    "    axes.set_xlim([x_lim[0], x_lim[1]*propotion])\n",
    "\n",
    "\"\"\"\n",
    " Draw plot using Matplotlib\n",
    "\"\"\"\n",
    "def draw_plot_func(dictionary, n_classes, window_title, plot_title, x_label, output_path, to_show, plot_color, true_p_bar):\n",
    "    # sort the dictionary by decreasing value, into a list of tuples\n",
    "    sorted_dic_by_value = sorted(dictionary.items(), key=operator.itemgetter(1))\n",
    "    # unpacking the list of tuples into two lists\n",
    "    sorted_keys, sorted_values = zip(*sorted_dic_by_value)\n",
    "    # \n",
    "    if true_p_bar != \"\":\n",
    "        \"\"\"\n",
    "         Special case to draw in:\n",
    "            - green -> TP: True Positives (object detected and matches ground-truth)\n",
    "            - red -> FP: False Positives (object detected but does not match ground-truth)\n",
    "            - orange -> FN: False Negatives (object not detected but present in the ground-truth)\n",
    "        \"\"\"\n",
    "        fp_sorted = []\n",
    "        tp_sorted = []\n",
    "        for key in sorted_keys:\n",
    "            fp_sorted.append(dictionary[key] - true_p_bar[key])\n",
    "            tp_sorted.append(true_p_bar[key])\n",
    "        plt.barh(range(n_classes), fp_sorted, align='center', color='crimson', label='False Positive')\n",
    "        plt.barh(range(n_classes), tp_sorted, align='center', color='forestgreen', label='True Positive', left=fp_sorted)\n",
    "        # add legend\n",
    "        plt.legend(loc='lower right')\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            fp_val = fp_sorted[i]\n",
    "            tp_val = tp_sorted[i]\n",
    "            fp_str_val = \" \" + str(fp_val)\n",
    "            tp_str_val = fp_str_val + \" \" + str(tp_val)\n",
    "            # trick to paint multicolor with offset:\n",
    "            # first paint everything and then repaint the first number\n",
    "            t = plt.text(val, i, tp_str_val, color='forestgreen', va='center', fontweight='bold')\n",
    "            plt.text(val, i, fp_str_val, color='crimson', va='center', fontweight='bold')\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    else:\n",
    "        plt.barh(range(n_classes), sorted_values, color=plot_color)\n",
    "        \"\"\"\n",
    "         Write number on side of bar\n",
    "        \"\"\"\n",
    "        fig = plt.gcf() # gcf - get current figure\n",
    "        axes = plt.gca()\n",
    "        r = fig.canvas.get_renderer()\n",
    "        for i, val in enumerate(sorted_values):\n",
    "            str_val = \" \" + str(val) # add a space before\n",
    "            if val < 1.0:\n",
    "                str_val = \" {0:.2f}\".format(val)\n",
    "            t = plt.text(val, i, str_val, color=plot_color, va='center', fontweight='bold')\n",
    "            # re-set axes to show number inside the figure\n",
    "            if i == (len(sorted_values)-1): # largest bar\n",
    "                adjust_axes(r, t, fig, axes)\n",
    "    # set window title\n",
    "    fig.canvas.set_window_title(window_title)\n",
    "    # write classes in y axis\n",
    "    tick_font_size = 12\n",
    "    plt.yticks(range(n_classes), sorted_keys, fontsize=tick_font_size)\n",
    "    \"\"\"\n",
    "     Re-scale height accordingly\n",
    "    \"\"\"\n",
    "    init_height = fig.get_figheight()\n",
    "    # comput the matrix height in points and inches\n",
    "    dpi = fig.dpi\n",
    "    height_pt = n_classes * (tick_font_size * 1.4) # 1.4 (some spacing)\n",
    "    height_in = height_pt / dpi\n",
    "    # compute the required figure height \n",
    "    top_margin = 0.15 # in percentage of the figure height\n",
    "    bottom_margin = 0.05 # in percentage of the figure height\n",
    "    figure_height = height_in / (1 - top_margin - bottom_margin)\n",
    "    # set new height\n",
    "    if figure_height > init_height:\n",
    "        fig.set_figheight(figure_height)\n",
    "\n",
    "    # set plot title\n",
    "    plt.title(plot_title, fontsize=14)\n",
    "    # set axis titles\n",
    "    # plt.xlabel('classes')\n",
    "    plt.xlabel(x_label, fontsize='large')\n",
    "    # adjust size of window\n",
    "    fig.tight_layout()\n",
    "    # save the plot\n",
    "    fig.savefig(output_path)\n",
    "    # show image\n",
    "    if to_show:\n",
    "        plt.show()\n",
    "    # close the plot\n",
    "    plt.close()\n",
    "\n",
    "def get_map(MINOVERLAP, draw_plot, score_threhold=0.5, path = './map_out'):\n",
    "    GT_PATH             = os.path.join(path, 'ground-truth')\n",
    "    DR_PATH             = os.path.join(path, 'detection-results')\n",
    "    IMG_PATH            = os.path.join(path, 'images-optional')\n",
    "    TEMP_FILES_PATH     = os.path.join(path, '.temp_files')\n",
    "    RESULTS_FILES_PATH  = os.path.join(path, 'results')\n",
    "\n",
    "    show_animation = True\n",
    "    if os.path.exists(IMG_PATH): \n",
    "        for dirpath, dirnames, files in os.walk(IMG_PATH):\n",
    "            if not files:\n",
    "                show_animation = False\n",
    "    else:\n",
    "        show_animation = False\n",
    "\n",
    "    if not os.path.exists(TEMP_FILES_PATH):\n",
    "        os.makedirs(TEMP_FILES_PATH)\n",
    "        \n",
    "    if os.path.exists(RESULTS_FILES_PATH):\n",
    "        shutil.rmtree(RESULTS_FILES_PATH)\n",
    "    else:\n",
    "        os.makedirs(RESULTS_FILES_PATH)\n",
    "    if draw_plot:\n",
    "        try:\n",
    "            matplotlib.use('TkAgg')\n",
    "        except:\n",
    "            pass\n",
    "        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"AP\"))\n",
    "        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"F1\"))\n",
    "        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"Recall\"))\n",
    "        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"Precision\"))\n",
    "    if show_animation:\n",
    "        os.makedirs(os.path.join(RESULTS_FILES_PATH, \"images\", \"detections_one_by_one\"))\n",
    "\n",
    "    ground_truth_files_list = glob.glob(GT_PATH + '/*.txt')\n",
    "    if len(ground_truth_files_list) == 0:\n",
    "        error(\"Error: No ground-truth files found!\")\n",
    "    ground_truth_files_list.sort()\n",
    "    gt_counter_per_class     = {}\n",
    "    counter_images_per_class = {}\n",
    "\n",
    "    for txt_file in ground_truth_files_list:\n",
    "        file_id     = txt_file.split(\".txt\", 1)[0]\n",
    "        file_id     = os.path.basename(os.path.normpath(file_id))\n",
    "        temp_path   = os.path.join(DR_PATH, (file_id + \".txt\"))\n",
    "        if not os.path.exists(temp_path):\n",
    "            error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "            error(error_msg)\n",
    "        lines_list      = file_lines_to_list(txt_file)\n",
    "        bounding_boxes  = []\n",
    "        is_difficult    = False\n",
    "        already_seen_classes = []\n",
    "        for line in lines_list:\n",
    "            try:\n",
    "                if \"difficult\" in line:\n",
    "                    class_name, left, top, right, bottom, _difficult = line.split()\n",
    "                    is_difficult = True\n",
    "                else:\n",
    "                    class_name, left, top, right, bottom = line.split()\n",
    "            except:\n",
    "                if \"difficult\" in line:\n",
    "                    line_split  = line.split()\n",
    "                    _difficult  = line_split[-1]\n",
    "                    bottom      = line_split[-2]\n",
    "                    right       = line_split[-3]\n",
    "                    top         = line_split[-4]\n",
    "                    left        = line_split[-5]\n",
    "                    class_name  = \"\"\n",
    "                    for name in line_split[:-5]:\n",
    "                        class_name += name + \" \"\n",
    "                    class_name  = class_name[:-1]\n",
    "                    is_difficult = True\n",
    "                else:\n",
    "                    line_split  = line.split()\n",
    "                    bottom      = line_split[-1]\n",
    "                    right       = line_split[-2]\n",
    "                    top         = line_split[-3]\n",
    "                    left        = line_split[-4]\n",
    "                    class_name  = \"\"\n",
    "                    for name in line_split[:-4]:\n",
    "                        class_name += name + \" \"\n",
    "                    class_name = class_name[:-1]\n",
    "\n",
    "            bbox = left + \" \" + top + \" \" + right + \" \" + bottom\n",
    "            if is_difficult:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False, \"difficult\":True})\n",
    "                is_difficult = False\n",
    "            else:\n",
    "                bounding_boxes.append({\"class_name\":class_name, \"bbox\":bbox, \"used\":False})\n",
    "                if class_name in gt_counter_per_class:\n",
    "                    gt_counter_per_class[class_name] += 1\n",
    "                else:\n",
    "                    gt_counter_per_class[class_name] = 1\n",
    "\n",
    "                if class_name not in already_seen_classes:\n",
    "                    if class_name in counter_images_per_class:\n",
    "                        counter_images_per_class[class_name] += 1\n",
    "                    else:\n",
    "                        counter_images_per_class[class_name] = 1\n",
    "                    already_seen_classes.append(class_name)\n",
    "\n",
    "        with open(TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\", 'w') as outfile:\n",
    "            json.dump(bounding_boxes, outfile)\n",
    "\n",
    "    gt_classes  = list(gt_counter_per_class.keys())\n",
    "    gt_classes  = sorted(gt_classes)\n",
    "    n_classes   = len(gt_classes)\n",
    "\n",
    "    dr_files_list = glob.glob(DR_PATH + '/*.txt')\n",
    "    dr_files_list.sort()\n",
    "    for class_index, class_name in enumerate(gt_classes):\n",
    "        bounding_boxes = []\n",
    "        for txt_file in dr_files_list:\n",
    "            file_id = txt_file.split(\".txt\",1)[0]\n",
    "            file_id = os.path.basename(os.path.normpath(file_id))\n",
    "            temp_path = os.path.join(GT_PATH, (file_id + \".txt\"))\n",
    "            if class_index == 0:\n",
    "                if not os.path.exists(temp_path):\n",
    "                    error_msg = \"Error. File not found: {}\\n\".format(temp_path)\n",
    "                    error(error_msg)\n",
    "            lines = file_lines_to_list(txt_file)\n",
    "            for line in lines:\n",
    "                try:\n",
    "                    tmp_class_name, confidence, left, top, right, bottom = line.split()\n",
    "                except:\n",
    "                    line_split      = line.split()\n",
    "                    bottom          = line_split[-1]\n",
    "                    right           = line_split[-2]\n",
    "                    top             = line_split[-3]\n",
    "                    left            = line_split[-4]\n",
    "                    confidence      = line_split[-5]\n",
    "                    tmp_class_name  = \"\"\n",
    "                    for name in line_split[:-5]:\n",
    "                        tmp_class_name += name + \" \"\n",
    "                    tmp_class_name  = tmp_class_name[:-1]\n",
    "\n",
    "                if tmp_class_name == class_name:\n",
    "                    bbox = left + \" \" + top + \" \" + right + \" \" +bottom\n",
    "                    bounding_boxes.append({\"confidence\":confidence, \"file_id\":file_id, \"bbox\":bbox})\n",
    "\n",
    "        bounding_boxes.sort(key=lambda x:float(x['confidence']), reverse=True)\n",
    "        with open(TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\", 'w') as outfile:\n",
    "            json.dump(bounding_boxes, outfile)\n",
    "\n",
    "    sum_AP = 0.0\n",
    "    ap_dictionary = {}\n",
    "    lamr_dictionary = {}\n",
    "    with open(RESULTS_FILES_PATH + \"/results.txt\", 'w') as results_file:\n",
    "        results_file.write(\"# AP and precision/recall per class\\n\")\n",
    "        count_true_positives = {}\n",
    "\n",
    "        for class_index, class_name in enumerate(gt_classes):\n",
    "            count_true_positives[class_name] = 0\n",
    "            dr_file = TEMP_FILES_PATH + \"/\" + class_name + \"_dr.json\"\n",
    "            dr_data = json.load(open(dr_file))\n",
    "\n",
    "            nd          = len(dr_data)\n",
    "            tp          = [0] * nd\n",
    "            fp          = [0] * nd\n",
    "            score       = [0] * nd\n",
    "            score_threhold_idx = 0\n",
    "            for idx, detection in enumerate(dr_data):\n",
    "                file_id     = detection[\"file_id\"]\n",
    "                score[idx]  = float(detection[\"confidence\"])\n",
    "                if score[idx] >= score_threhold:\n",
    "                    score_threhold_idx = idx\n",
    "\n",
    "                if show_animation:\n",
    "                    ground_truth_img = glob.glob1(IMG_PATH, file_id + \".*\")\n",
    "                    if len(ground_truth_img) == 0:\n",
    "                        error(\"Error. Image not found with id: \" + file_id)\n",
    "                    elif len(ground_truth_img) > 1:\n",
    "                        error(\"Error. Multiple image with id: \" + file_id)\n",
    "                    else:\n",
    "                        img = cv2.imread(IMG_PATH + \"/\" + ground_truth_img[0])\n",
    "                        img_cumulative_path = RESULTS_FILES_PATH + \"/images/\" + ground_truth_img[0]\n",
    "                        if os.path.isfile(img_cumulative_path):\n",
    "                            img_cumulative = cv2.imread(img_cumulative_path)\n",
    "                        else:\n",
    "                            img_cumulative = img.copy()\n",
    "                        bottom_border = 60\n",
    "                        BLACK = [0, 0, 0]\n",
    "                        img = cv2.copyMakeBorder(img, 0, bottom_border, 0, 0, cv2.BORDER_CONSTANT, value=BLACK)\n",
    "\n",
    "                gt_file             = TEMP_FILES_PATH + \"/\" + file_id + \"_ground_truth.json\"\n",
    "                ground_truth_data   = json.load(open(gt_file))\n",
    "                ovmax       = -1\n",
    "                gt_match    = -1\n",
    "                bb          = [float(x) for x in detection[\"bbox\"].split()]\n",
    "                for obj in ground_truth_data:\n",
    "                    if obj[\"class_name\"] == class_name:\n",
    "                        bbgt    = [ float(x) for x in obj[\"bbox\"].split() ]\n",
    "                        bi      = [max(bb[0],bbgt[0]), max(bb[1],bbgt[1]), min(bb[2],bbgt[2]), min(bb[3],bbgt[3])]\n",
    "                        iw      = bi[2] - bi[0] + 1\n",
    "                        ih      = bi[3] - bi[1] + 1\n",
    "                        if iw > 0 and ih > 0:\n",
    "                            ua = (bb[2] - bb[0] + 1) * (bb[3] - bb[1] + 1) + (bbgt[2] - bbgt[0]\n",
    "                                            + 1) * (bbgt[3] - bbgt[1] + 1) - iw * ih\n",
    "                            ov = iw * ih / ua\n",
    "                            if ov > ovmax:\n",
    "                                ovmax = ov\n",
    "                                gt_match = obj\n",
    "\n",
    "                if show_animation:\n",
    "                    status = \"NO MATCH FOUND!\" \n",
    "                    \n",
    "                min_overlap = MINOVERLAP\n",
    "                if ovmax >= min_overlap:\n",
    "                    if \"difficult\" not in gt_match:\n",
    "                        if not bool(gt_match[\"used\"]):\n",
    "                            tp[idx] = 1\n",
    "                            gt_match[\"used\"] = True\n",
    "                            count_true_positives[class_name] += 1\n",
    "                            with open(gt_file, 'w') as f:\n",
    "                                    f.write(json.dumps(ground_truth_data))\n",
    "                            if show_animation:\n",
    "                                status = \"MATCH!\"\n",
    "                        else:\n",
    "                            fp[idx] = 1\n",
    "                            if show_animation:\n",
    "                                status = \"REPEATED MATCH!\"\n",
    "                else:\n",
    "                    fp[idx] = 1\n",
    "                    if ovmax > 0:\n",
    "                        status = \"INSUFFICIENT OVERLAP\"\n",
    "\n",
    "                \"\"\"\n",
    "                Draw image to show animation\n",
    "                \"\"\"\n",
    "                if show_animation:\n",
    "                    height, widht = img.shape[:2]\n",
    "                    white           = (255,255,255)\n",
    "                    light_blue      = (255,200,100)\n",
    "                    green           = (0,255,0)\n",
    "                    light_red       = (30,30,255)\n",
    "                    margin          = 10\n",
    "                    # 1nd line\n",
    "                    v_pos           = int(height - margin - (bottom_border / 2.0))\n",
    "                    text            = \"Image: \" + ground_truth_img[0] + \" \"\n",
    "                    img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                    text            = \"Class [\" + str(class_index) + \"/\" + str(n_classes) + \"]: \" + class_name + \" \"\n",
    "                    img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), light_blue, line_width)\n",
    "                    if ovmax != -1:\n",
    "                        color       = light_red\n",
    "                        if status   == \"INSUFFICIENT OVERLAP\":\n",
    "                            text    = \"IoU: {0:.2f}% \".format(ovmax*100) + \"< {0:.2f}% \".format(min_overlap*100)\n",
    "                        else:\n",
    "                            text    = \"IoU: {0:.2f}% \".format(ovmax*100) + \">= {0:.2f}% \".format(min_overlap*100)\n",
    "                            color   = green\n",
    "                        img, _ = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "                    # 2nd line\n",
    "                    v_pos           += int(bottom_border / 2.0)\n",
    "                    rank_pos        = str(idx+1)\n",
    "                    text            = \"Detection #rank: \" + rank_pos + \" confidence: {0:.2f}% \".format(float(detection[\"confidence\"])*100)\n",
    "                    img, line_width = draw_text_in_image(img, text, (margin, v_pos), white, 0)\n",
    "                    color           = light_red\n",
    "                    if status == \"MATCH!\":\n",
    "                        color = green\n",
    "                    text            = \"Result: \" + status + \" \"\n",
    "                    img, line_width = draw_text_in_image(img, text, (margin + line_width, v_pos), color, line_width)\n",
    "\n",
    "                    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                    if ovmax > 0: \n",
    "                        bbgt = [ int(round(float(x))) for x in gt_match[\"bbox\"].split() ]\n",
    "                        cv2.rectangle(img,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                        cv2.rectangle(img_cumulative,(bbgt[0],bbgt[1]),(bbgt[2],bbgt[3]),light_blue,2)\n",
    "                        cv2.putText(img_cumulative, class_name, (bbgt[0],bbgt[1] - 5), font, 0.6, light_blue, 1, cv2.LINE_AA)\n",
    "                    bb = [int(i) for i in bb]\n",
    "                    cv2.rectangle(img,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                    cv2.rectangle(img_cumulative,(bb[0],bb[1]),(bb[2],bb[3]),color,2)\n",
    "                    cv2.putText(img_cumulative, class_name, (bb[0],bb[1] - 5), font, 0.6, color, 1, cv2.LINE_AA)\n",
    "\n",
    "                    cv2.imshow(\"Animation\", img)\n",
    "                    cv2.waitKey(20) \n",
    "                    output_img_path = RESULTS_FILES_PATH + \"/images/detections_one_by_one/\" + class_name + \"_detection\" + str(idx) + \".jpg\"\n",
    "                    cv2.imwrite(output_img_path, img)\n",
    "                    cv2.imwrite(img_cumulative_path, img_cumulative)\n",
    "\n",
    "            cumsum = 0\n",
    "            for idx, val in enumerate(fp):\n",
    "                fp[idx] += cumsum\n",
    "                cumsum += val\n",
    "                \n",
    "            cumsum = 0\n",
    "            for idx, val in enumerate(tp):\n",
    "                tp[idx] += cumsum\n",
    "                cumsum += val\n",
    "\n",
    "            rec = tp[:]\n",
    "            for idx, val in enumerate(tp):\n",
    "                rec[idx] = float(tp[idx]) / np.maximum(gt_counter_per_class[class_name], 1)\n",
    "\n",
    "            prec = tp[:]\n",
    "            for idx, val in enumerate(tp):\n",
    "                prec[idx] = float(tp[idx]) / np.maximum((fp[idx] + tp[idx]), 1)\n",
    "\n",
    "            ap, mrec, mprec = voc_ap(rec[:], prec[:])\n",
    "            F1  = np.array(rec)*np.array(prec)*2 / np.where((np.array(prec)+np.array(rec))==0, 1, (np.array(prec)+np.array(rec)))\n",
    "\n",
    "            sum_AP  += ap\n",
    "            text    = \"{0:.2f}%\".format(ap*100) + \" = \" + class_name + \" AP \" #class_name + \" AP = {0:.2f}%\".format(ap*100)\n",
    "\n",
    "            if len(prec)>0:\n",
    "                F1_text         = \"{0:.2f}\".format(F1[score_threhold_idx]) + \" = \" + class_name + \" F1 \"\n",
    "                Recall_text     = \"{0:.2f}%\".format(rec[score_threhold_idx]*100) + \" = \" + class_name + \" Recall \"\n",
    "                Precision_text  = \"{0:.2f}%\".format(prec[score_threhold_idx]*100) + \" = \" + class_name + \" Precision \"\n",
    "            else:\n",
    "                F1_text         = \"0.00\" + \" = \" + class_name + \" F1 \" \n",
    "                Recall_text     = \"0.00%\" + \" = \" + class_name + \" Recall \" \n",
    "                Precision_text  = \"0.00%\" + \" = \" + class_name + \" Precision \" \n",
    "\n",
    "            rounded_prec    = [ '%.2f' % elem for elem in prec ]\n",
    "            rounded_rec     = [ '%.2f' % elem for elem in rec ]\n",
    "            results_file.write(text + \"\\n Precision: \" + str(rounded_prec) + \"\\n Recall :\" + str(rounded_rec) + \"\\n\\n\")\n",
    "            \n",
    "            if len(prec)>0:\n",
    "                print(text + \"\\t||\\tscore_threhold=\" + str(score_threhold) + \" : \" + \"F1=\" + \"{0:.2f}\".format(F1[score_threhold_idx])\\\n",
    "                    + \" ; Recall=\" + \"{0:.2f}%\".format(rec[score_threhold_idx]*100) + \" ; Precision=\" + \"{0:.2f}%\".format(prec[score_threhold_idx]*100))\n",
    "            else:\n",
    "                print(text + \"\\t||\\tscore_threhold=\" + str(score_threhold) + \" : \" + \"F1=0.00% ; Recall=0.00% ; Precision=0.00%\")\n",
    "            ap_dictionary[class_name] = ap\n",
    "\n",
    "            n_images = counter_images_per_class[class_name]\n",
    "            lamr, mr, fppi = log_average_miss_rate(np.array(rec), np.array(fp), n_images)\n",
    "            lamr_dictionary[class_name] = lamr\n",
    "\n",
    "            if draw_plot:\n",
    "                plt.plot(rec, prec, '-o')\n",
    "                area_under_curve_x = mrec[:-1] + [mrec[-2]] + [mrec[-1]]\n",
    "                area_under_curve_y = mprec[:-1] + [0.0] + [mprec[-1]]\n",
    "                plt.fill_between(area_under_curve_x, 0, area_under_curve_y, alpha=0.2, edgecolor='r')\n",
    "\n",
    "                fig = plt.gcf()\n",
    "                fig.canvas.set_window_title('AP ' + class_name)\n",
    "\n",
    "                plt.title('class: ' + text)\n",
    "                plt.xlabel('Recall')\n",
    "                plt.ylabel('Precision')\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([0.0,1.0])\n",
    "                axes.set_ylim([0.0,1.05]) \n",
    "                fig.savefig(RESULTS_FILES_PATH + \"/AP/\" + class_name + \".png\")\n",
    "                plt.cla()\n",
    "\n",
    "                plt.plot(score, F1, \"-\", color='orangered')\n",
    "                plt.title('class: ' + F1_text + \"\\nscore_threhold=\" + str(score_threhold))\n",
    "                plt.xlabel('Score_Threhold')\n",
    "                plt.ylabel('F1')\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([0.0,1.0])\n",
    "                axes.set_ylim([0.0,1.05])\n",
    "                fig.savefig(RESULTS_FILES_PATH + \"/F1/\" + class_name + \".png\")\n",
    "                plt.cla()\n",
    "\n",
    "                plt.plot(score, rec, \"-H\", color='gold')\n",
    "                plt.title('class: ' + Recall_text + \"\\nscore_threhold=\" + str(score_threhold))\n",
    "                plt.xlabel('Score_Threhold')\n",
    "                plt.ylabel('Recall')\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([0.0,1.0])\n",
    "                axes.set_ylim([0.0,1.05])\n",
    "                fig.savefig(RESULTS_FILES_PATH + \"/Recall/\" + class_name + \".png\")\n",
    "                plt.cla()\n",
    "\n",
    "                plt.plot(score, prec, \"-s\", color='palevioletred')\n",
    "                plt.title('class: ' + Precision_text + \"\\nscore_threhold=\" + str(score_threhold))\n",
    "                plt.xlabel('Score_Threhold')\n",
    "                plt.ylabel('Precision')\n",
    "                axes = plt.gca()\n",
    "                axes.set_xlim([0.0,1.0])\n",
    "                axes.set_ylim([0.0,1.05])\n",
    "                fig.savefig(RESULTS_FILES_PATH + \"/Precision/\" + class_name + \".png\")\n",
    "                plt.cla()\n",
    "                \n",
    "        if show_animation:\n",
    "            cv2.destroyAllWindows()\n",
    "        if n_classes == 0:\n",
    "            print(\"未检测到任何种类，请检查标签信息与get_map.py中的classes_path是否修改。\")\n",
    "            return 0\n",
    "        results_file.write(\"\\n# mAP of all classes\\n\")\n",
    "        mAP     = sum_AP / n_classes\n",
    "        text    = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "        results_file.write(text + \"\\n\")\n",
    "        print(text)\n",
    "\n",
    "    shutil.rmtree(TEMP_FILES_PATH)\n",
    "\n",
    "    \"\"\"\n",
    "    Count total of detection-results\n",
    "    \"\"\"\n",
    "    det_counter_per_class = {}\n",
    "    for txt_file in dr_files_list:\n",
    "        lines_list = file_lines_to_list(txt_file)\n",
    "        for line in lines_list:\n",
    "            class_name = line.split()[0]\n",
    "            if class_name in det_counter_per_class:\n",
    "                det_counter_per_class[class_name] += 1\n",
    "            else:\n",
    "                det_counter_per_class[class_name] = 1\n",
    "    dr_classes = list(det_counter_per_class.keys())\n",
    "\n",
    "    \"\"\"\n",
    "    Write number of ground-truth objects per class to results.txt\n",
    "    \"\"\"\n",
    "    with open(RESULTS_FILES_PATH + \"/results.txt\", 'a') as results_file:\n",
    "        results_file.write(\"\\n# Number of ground-truth objects per class\\n\")\n",
    "        for class_name in sorted(gt_counter_per_class):\n",
    "            results_file.write(class_name + \": \" + str(gt_counter_per_class[class_name]) + \"\\n\")\n",
    "\n",
    "    \"\"\"\n",
    "    Finish counting true positives\n",
    "    \"\"\"\n",
    "    for class_name in dr_classes:\n",
    "        if class_name not in gt_classes:\n",
    "            count_true_positives[class_name] = 0\n",
    "\n",
    "    \"\"\"\n",
    "    Write number of detected objects per class to results.txt\n",
    "    \"\"\"\n",
    "    with open(RESULTS_FILES_PATH + \"/results.txt\", 'a') as results_file:\n",
    "        results_file.write(\"\\n# Number of detected objects per class\\n\")\n",
    "        for class_name in sorted(dr_classes):\n",
    "            n_det = det_counter_per_class[class_name]\n",
    "            text = class_name + \": \" + str(n_det)\n",
    "            text += \" (tp:\" + str(count_true_positives[class_name]) + \"\"\n",
    "            text += \", fp:\" + str(n_det - count_true_positives[class_name]) + \")\\n\"\n",
    "            results_file.write(text)\n",
    "\n",
    "    \"\"\"\n",
    "    Plot the total number of occurences of each class in the ground-truth\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "        window_title = \"ground-truth-info\"\n",
    "        plot_title = \"ground-truth\\n\"\n",
    "        plot_title += \"(\" + str(len(ground_truth_files_list)) + \" files and \" + str(n_classes) + \" classes)\"\n",
    "        x_label = \"Number of objects per class\"\n",
    "        output_path = RESULTS_FILES_PATH + \"/ground-truth-info.png\"\n",
    "        to_show = False\n",
    "        plot_color = 'forestgreen'\n",
    "        draw_plot_func(\n",
    "            gt_counter_per_class,\n",
    "            n_classes,\n",
    "            window_title,\n",
    "            plot_title,\n",
    "            x_label,\n",
    "            output_path,\n",
    "            to_show,\n",
    "            plot_color,\n",
    "            '',\n",
    "            )\n",
    "\n",
    "    # \"\"\"\n",
    "    # Plot the total number of occurences of each class in the \"detection-results\" folder\n",
    "    # \"\"\"\n",
    "    # if draw_plot:\n",
    "    #     window_title = \"detection-results-info\"\n",
    "    #     # Plot title\n",
    "    #     plot_title = \"detection-results\\n\"\n",
    "    #     plot_title += \"(\" + str(len(dr_files_list)) + \" files and \"\n",
    "    #     count_non_zero_values_in_dictionary = sum(int(x) > 0 for x in list(det_counter_per_class.values()))\n",
    "    #     plot_title += str(count_non_zero_values_in_dictionary) + \" detected classes)\"\n",
    "    #     # end Plot title\n",
    "    #     x_label = \"Number of objects per class\"\n",
    "    #     output_path = RESULTS_FILES_PATH + \"/detection-results-info.png\"\n",
    "    #     to_show = False\n",
    "    #     plot_color = 'forestgreen'\n",
    "    #     true_p_bar = count_true_positives\n",
    "    #     draw_plot_func(\n",
    "    #         det_counter_per_class,\n",
    "    #         len(det_counter_per_class),\n",
    "    #         window_title,\n",
    "    #         plot_title,\n",
    "    #         x_label,\n",
    "    #         output_path,\n",
    "    #         to_show,\n",
    "    #         plot_color,\n",
    "    #         true_p_bar\n",
    "    #         )\n",
    "\n",
    "    \"\"\"\n",
    "    Draw log-average miss rate plot (Show lamr of all classes in decreasing order)\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "        window_title = \"lamr\"\n",
    "        plot_title = \"log-average miss rate\"\n",
    "        x_label = \"log-average miss rate\"\n",
    "        output_path = RESULTS_FILES_PATH + \"/lamr.png\"\n",
    "        to_show = False\n",
    "        plot_color = 'royalblue'\n",
    "        draw_plot_func(\n",
    "            lamr_dictionary,\n",
    "            n_classes,\n",
    "            window_title,\n",
    "            plot_title,\n",
    "            x_label,\n",
    "            output_path,\n",
    "            to_show,\n",
    "            plot_color,\n",
    "            \"\"\n",
    "            )\n",
    "\n",
    "    \"\"\"\n",
    "    Draw mAP plot (Show AP's of all classes in decreasing order)\n",
    "    \"\"\"\n",
    "    if draw_plot:\n",
    "        window_title = \"mAP\"\n",
    "        plot_title = \"mAP = {0:.2f}%\".format(mAP*100)\n",
    "        x_label = \"Average Precision\"\n",
    "        output_path = RESULTS_FILES_PATH + \"/mAP.png\"\n",
    "        to_show = True\n",
    "        plot_color = 'royalblue'\n",
    "        draw_plot_func(\n",
    "            ap_dictionary,\n",
    "            n_classes,\n",
    "            window_title,\n",
    "            plot_title,\n",
    "            x_label,\n",
    "            output_path,\n",
    "            to_show,\n",
    "            plot_color,\n",
    "            \"\"\n",
    "            )\n",
    "    return mAP\n",
    "\n",
    "def preprocess_gt(gt_path, class_names):\n",
    "    image_ids   = os.listdir(gt_path)\n",
    "    results = {}\n",
    "\n",
    "    images = []\n",
    "    bboxes = []\n",
    "    for i, image_id in enumerate(image_ids):\n",
    "        lines_list      = file_lines_to_list(os.path.join(gt_path, image_id))\n",
    "        boxes_per_image = []\n",
    "        image           = {}\n",
    "        image_id        = os.path.splitext(image_id)[0]\n",
    "        image['file_name'] = image_id + '.jpg'\n",
    "        image['width']     = 1\n",
    "        image['height']    = 1\n",
    "        #-----------------------------------------------------------------#\n",
    "        #   感谢 多学学英语吧 的提醒\n",
    "        #   解决了'Results do not correspond to current coco set'问题\n",
    "        #-----------------------------------------------------------------#\n",
    "        image['id']        = str(image_id)\n",
    "\n",
    "        for line in lines_list:\n",
    "            difficult = 0 \n",
    "            if \"difficult\" in line:\n",
    "                line_split  = line.split()\n",
    "                left, top, right, bottom, _difficult = line_split[-5:]\n",
    "                class_name  = \"\"\n",
    "                for name in line_split[:-5]:\n",
    "                    class_name += name + \" \"\n",
    "                class_name  = class_name[:-1]\n",
    "                difficult = 1\n",
    "            else:\n",
    "                line_split  = line.split()\n",
    "                left, top, right, bottom = line_split[-4:]\n",
    "                class_name  = \"\"\n",
    "                for name in line_split[:-4]:\n",
    "                    class_name += name + \" \"\n",
    "                class_name = class_name[:-1]\n",
    "            \n",
    "            left, top, right, bottom = float(left), float(top), float(right), float(bottom)\n",
    "            if class_name not in class_names:\n",
    "                continue\n",
    "            cls_id  = class_names.index(class_name) + 1\n",
    "            bbox    = [left, top, right - left, bottom - top, difficult, str(image_id), cls_id, (right - left) * (bottom - top) - 10.0]\n",
    "            boxes_per_image.append(bbox)\n",
    "        images.append(image)\n",
    "        bboxes.extend(boxes_per_image)\n",
    "    results['images']        = images\n",
    "\n",
    "    categories = []\n",
    "    for i, cls in enumerate(class_names):\n",
    "        category = {}\n",
    "        category['supercategory']   = cls\n",
    "        category['name']            = cls\n",
    "        category['id']              = i + 1\n",
    "        categories.append(category)\n",
    "    results['categories']   = categories\n",
    "\n",
    "    annotations = []\n",
    "    for i, box in enumerate(bboxes):\n",
    "        annotation = {}\n",
    "        annotation['area']        = box[-1]\n",
    "        annotation['category_id'] = box[-2]\n",
    "        annotation['image_id']    = box[-3]\n",
    "        annotation['iscrowd']     = box[-4]\n",
    "        annotation['bbox']        = box[:4]\n",
    "        annotation['id']          = i\n",
    "        annotations.append(annotation)\n",
    "    results['annotations'] = annotations\n",
    "    return results\n",
    "\n",
    "def preprocess_dr(dr_path, class_names):\n",
    "    image_ids = os.listdir(dr_path)\n",
    "    results = []\n",
    "    for image_id in image_ids:\n",
    "        lines_list      = file_lines_to_list(os.path.join(dr_path, image_id))\n",
    "        image_id        = os.path.splitext(image_id)[0]\n",
    "        for line in lines_list:\n",
    "            line_split  = line.split()\n",
    "            confidence, left, top, right, bottom = line_split[-5:]\n",
    "            class_name  = \"\"\n",
    "            for name in line_split[:-5]:\n",
    "                class_name += name + \" \"\n",
    "            class_name  = class_name[:-1]\n",
    "            left, top, right, bottom = float(left), float(top), float(right), float(bottom)\n",
    "            result                  = {}\n",
    "            result[\"image_id\"]      = str(image_id)\n",
    "            if class_name not in class_names:\n",
    "                continue\n",
    "            result[\"category_id\"]   = class_names.index(class_name) + 1\n",
    "            result[\"bbox\"]          = [left, top, right - left, bottom - top]\n",
    "            result[\"score\"]         = float(confidence)\n",
    "            results.append(result)\n",
    "    return results\n",
    " \n",
    "def get_coco_map(class_names, path):\n",
    "    GT_PATH     = os.path.join(path, 'ground-truth')\n",
    "    DR_PATH     = os.path.join(path, 'detection-results')\n",
    "    COCO_PATH   = os.path.join(path, 'coco_eval')\n",
    "\n",
    "    if not os.path.exists(COCO_PATH):\n",
    "        os.makedirs(COCO_PATH)\n",
    "\n",
    "    GT_JSON_PATH = os.path.join(COCO_PATH, 'instances_gt.json')\n",
    "    DR_JSON_PATH = os.path.join(COCO_PATH, 'instances_dr.json')\n",
    "\n",
    "    with open(GT_JSON_PATH, \"w\") as f:\n",
    "        results_gt  = preprocess_gt(GT_PATH, class_names)\n",
    "        json.dump(results_gt, f, indent=4)\n",
    "\n",
    "    with open(DR_JSON_PATH, \"w\") as f:\n",
    "        results_dr  = preprocess_dr(DR_PATH, class_names)\n",
    "        json.dump(results_dr, f, indent=4)\n",
    "        if len(results_dr) == 0:\n",
    "            print(\"未检测到任何目标。\")\n",
    "            return [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "    cocoGt      = COCO(GT_JSON_PATH)\n",
    "    cocoDt      = cocoGt.loadRes(DR_JSON_PATH)\n",
    "    cocoEval    = COCOeval(cocoGt, cocoDt, 'bbox') \n",
    "    cocoEval.evaluate()\n",
    "    cocoEval.accumulate()\n",
    "    cocoEval.summarize()\n",
    "\n",
    "    return cocoEval.stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
