{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c237f5a8-0348-433d-a3ee-02b56f688ced",
   "metadata": {},
   "source": [
    "# 获取训练集和验证集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eb12fe-61c0-4ea7-bb56-13bcd9fed0ec",
   "metadata": {},
   "source": [
    "从图片文件夹中读取所有图片，然后按照一定比例（比如80%训练集 + 20%验证集）划分图片，并分别生成两个列表文件：train.txt 和 val.txt，用于训练和验证模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bf9ce11-9983-4094-888d-01717805d33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed: number of training samples 4008, number of validation samples 1003\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Image path.\n",
    "jpg_folder = 'VOCdevkit/VOC2007/JPEGImages'\n",
    "# Save path for train/val.\n",
    "save_folder = 'VOCdevkit/VOC2007/ImageSets/Main'\n",
    "\n",
    "# Split ratio.\n",
    "train_percent = 0.8  \n",
    "val_percent = 0.2    \n",
    "\n",
    "# Read all .jpg files under the JPEGImages directory.\n",
    "jpg_files = [f for f in os.listdir(jpg_folder) if f.endswith('.jpg')]\n",
    "image_ids = [os.path.splitext(f)[0] for f in jpg_files]\n",
    "\n",
    "# Shuffle the order.\n",
    "random.seed(0)  # random.seed(0)\n",
    "random.shuffle(image_ids)\n",
    "\n",
    "# Split according to the specified ratio.\n",
    "num_total = len(image_ids)\n",
    "num_train = int(num_total * train_percent)\n",
    "train_ids = image_ids[:num_train]\n",
    "val_ids = image_ids[num_train:]\n",
    "\n",
    "# Save train.txt.\n",
    "with open(os.path.join(save_folder, 'train.txt'), 'w') as f:\n",
    "    for id in train_ids:\n",
    "        f.write(id + '\\n')\n",
    "\n",
    "# Save val.txt.\n",
    "with open(os.path.join(save_folder, 'val.txt'), 'w') as f:\n",
    "    for id in val_ids:\n",
    "        f.write(id + '\\n')\n",
    "\n",
    "print(f\"Generation completed: number of training samples {len(train_ids)}, number of validation samples {len(val_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660ee09-56b4-4286-8ea1-64a2adbd9d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03db680-8494-4ce3-9ee9-e24a84145f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
