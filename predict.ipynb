{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c71ebc3d-1ac6-42fd-a3f9-7690e9e8e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from opencv-python) (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e538ed-5693-4693-8485-066e4e3073a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from import-ipynb) (8.30.0)\n",
      "Requirement already satisfied: nbformat in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (2.15.1)\n",
      "Requirement already satisfied: stack-data in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (5.7.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (308)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: executing in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: six in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from asttokens->stack-data->IPython->import-ipynb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "%run YOLOv3_Object_Detection.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5b80c0-aae9-4c3a-9a56-366ad50f84aa",
   "metadata": {},
   "source": [
    "# YOLOv3标检测项目的测试脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382e3626-5327-40fa-9dbd-c6e2a98d865f",
   "metadata": {},
   "source": [
    "用于对训练好的模型进行单张图片预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a9c6e3-8378-4350-9b93-5c612ad56564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs/best_epoch_weights.pth model, anchors, and classes loaded.\n",
      "Configurations:\n",
      "----------------------------------------------------------------------\n",
      "|                     keys |                                   values|\n",
      "----------------------------------------------------------------------\n",
      "|               model_path |              logs/best_epoch_weights.pth|\n",
      "|             classes_path |               model_data/voc_classes.txt|\n",
      "|             anchors_path |              model_data/yolo_anchors.txt|\n",
      "|             anchors_mask |        [[6, 7, 8], [3, 4, 5], [0, 1, 2]]|\n",
      "|              input_shape |                               [416, 416]|\n",
      "|               confidence |                                      0.5|\n",
      "|                  nms_iou |                                      0.3|\n",
      "|          letterbox_image |                                    False|\n",
      "|                     cuda |                                     True|\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input image filename: img/street.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03mIf you want to save the detected image, you can simply use r_image.save(\"img.jpg\"). Just modify it directly in predict.py. \u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput image filename:\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     28\u001b[0m         image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img)\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\torch_env\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Use predict.py to perform single image prediction.\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from YOLOv3_Object_Detection import YOLO\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    yolo = YOLO()\n",
    "    # The 'mode' is used to specify the testing mode:\n",
    "    # 'predict'           indicates single image prediction\n",
    "    mode = \"predict\"\n",
    "    # 'crop'              Specifies whether to crop the detected objects after single image prediction  \n",
    "    # 'count'             Specifies whether to count the number of detected objects  \n",
    "    # 'crop' and 'count' are only effective when mode='predict'\n",
    "    crop            = False\n",
    "    count           = False\n",
    "    \n",
    "    if mode == \"predict\":\n",
    "        '''\n",
    "        If you want to save the detected image, you can simply use r_image.save(\"img.jpg\"). Just modify it directly in predict.py. \n",
    "        '''\n",
    "        while True:\n",
    "            img = input('Input image filename:')\n",
    "            try:\n",
    "                image = Image.open(img)\n",
    "            except:\n",
    "                print('Open Error! Try again!')\n",
    "                continue\n",
    "            else:\n",
    "                r_image = yolo.detect_image(image, crop = crop, count=count)\n",
    "                r_image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9686ee5-e611-43fb-b9ef-eeb9296fc2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
