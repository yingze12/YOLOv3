{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85c50a7-21ec-41b9-8f68-b37016a72ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: import-ipynb in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (0.2)\n",
      "Requirement already satisfied: IPython in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from import-ipynb) (8.30.0)\n",
      "Requirement already satisfied: nbformat in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from import-ipynb) (5.10.4)\n",
      "Requirement already satisfied: decorator in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (2.15.1)\n",
      "Requirement already satisfied: stack-data in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (5.14.3)\n",
      "Requirement already satisfied: exceptiongroup in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from IPython->import-ipynb) (0.4.6)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (2.21.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (4.23.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from nbformat->import-ipynb) (5.7.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jedi>=0.16->IPython->import-ipynb) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.24.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (3.10.0)\n",
      "Requirement already satisfied: pywin32>=300 in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->import-ipynb) (308)\n",
      "Requirement already satisfied: wcwidth in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->IPython->import-ipynb) (0.2.5)\n",
      "Requirement already satisfied: executing in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.8.3)\n",
      "Requirement already satisfied: asttokens in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from stack-data->IPython->import-ipynb) (0.2.2)\n",
      "Requirement already satisfied: six in d:\\anaconda\\envs\\torch_env\\lib\\site-packages (from asttokens->stack-data->IPython->import-ipynb) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install import-ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f887486-8bb4-4326-90c8-d0ce25cfd0e5",
   "metadata": {},
   "source": [
    "# 在 YOLO训练过程中用于记录和评估模型性能的重要辅助类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e119215-5667-4198-a055-a563eeb1e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import scipy.signal\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import import_ipynb\n",
    "from utils import cvtColor, preprocess_input, resize_image\n",
    "from darknet import DecodeBox\n",
    "from utils_map import get_coco_map, get_map\n",
    "\n",
    "\n",
    "class LossHistory():\n",
    "    def __init__(self, log_dir, model, input_shape):\n",
    "        self.log_dir    = log_dir\n",
    "        self.losses     = []\n",
    "        self.val_loss   = []\n",
    "        \n",
    "        os.makedirs(self.log_dir)\n",
    "        self.writer     = SummaryWriter(self.log_dir)\n",
    "        try:\n",
    "            dummy_input     = torch.randn(2, 3, input_shape[0], input_shape[1])\n",
    "            self.writer.add_graph(model, dummy_input)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    def append_loss(self, epoch, loss, val_loss):\n",
    "        if not os.path.exists(self.log_dir):\n",
    "            os.makedirs(self.log_dir)\n",
    "\n",
    "        self.losses.append(loss)\n",
    "        self.val_loss.append(val_loss)\n",
    "\n",
    "        with open(os.path.join(self.log_dir, \"epoch_loss.txt\"), 'a') as f:\n",
    "            f.write(str(loss))\n",
    "            f.write(\"\\n\")\n",
    "        with open(os.path.join(self.log_dir, \"epoch_val_loss.txt\"), 'a') as f:\n",
    "            f.write(str(val_loss))\n",
    "            f.write(\"\\n\")\n",
    "\n",
    "        self.writer.add_scalar('loss', loss, epoch)\n",
    "        self.writer.add_scalar('val_loss', val_loss, epoch)\n",
    "        self.loss_plot()\n",
    "\n",
    "    def loss_plot(self):\n",
    "        iters = range(len(self.losses))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(iters, self.losses, 'red', linewidth = 2, label='train loss')\n",
    "        plt.plot(iters, self.val_loss, 'coral', linewidth = 2, label='val loss')\n",
    "        try:\n",
    "            if len(self.losses) < 25:\n",
    "                num = 5\n",
    "            else:\n",
    "                num = 15\n",
    "            \n",
    "            plt.plot(iters, scipy.signal.savgol_filter(self.losses, num, 3), 'green', linestyle = '--', linewidth = 2, label='smooth train loss')\n",
    "            plt.plot(iters, scipy.signal.savgol_filter(self.val_loss, num, 3), '#8B4513', linestyle = '--', linewidth = 2, label='smooth val loss')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "\n",
    "        plt.savefig(os.path.join(self.log_dir, \"epoch_loss.png\"))\n",
    "\n",
    "        plt.cla()\n",
    "        plt.close(\"all\")\n",
    "\n",
    "class EvalCallback():\n",
    "    def __init__(self, net, input_shape, anchors, anchors_mask, class_names, num_classes, val_lines, log_dir, cuda, \\\n",
    "            map_out_path=\".temp_map_out\", max_boxes=100, confidence=0.05, nms_iou=0.5, letterbox_image=True, MINOVERLAP=0.5, eval_flag=True, period=1):\n",
    "        super(EvalCallback, self).__init__()\n",
    "        \n",
    "        self.net                = net\n",
    "        self.input_shape        = input_shape\n",
    "        self.anchors            = anchors\n",
    "        self.anchors_mask       = anchors_mask\n",
    "        self.class_names        = class_names\n",
    "        self.num_classes        = num_classes\n",
    "        self.val_lines          = val_lines\n",
    "        self.log_dir            = log_dir\n",
    "        self.cuda               = cuda\n",
    "        self.map_out_path       = map_out_path\n",
    "        self.max_boxes          = max_boxes\n",
    "        self.confidence         = confidence\n",
    "        self.nms_iou            = nms_iou\n",
    "        self.letterbox_image    = letterbox_image\n",
    "        self.MINOVERLAP         = MINOVERLAP\n",
    "        self.eval_flag          = eval_flag\n",
    "        self.period             = period\n",
    "        \n",
    "        self.bbox_util          = DecodeBox(self.anchors, self.num_classes, (self.input_shape[0], self.input_shape[1]), self.anchors_mask)\n",
    "        \n",
    "        self.maps       = [0]\n",
    "        self.epoches    = [0]\n",
    "        if self.eval_flag:\n",
    "            with open(os.path.join(self.log_dir, \"epoch_map.txt\"), 'a') as f:\n",
    "                f.write(str(0))\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "    def get_map_txt(self, image_id, image, class_names, map_out_path):\n",
    "        f = open(os.path.join(map_out_path, \"detection-results/\"+image_id+\".txt\"), \"w\", encoding='utf-8') \n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "        image       = cvtColor(image)\n",
    "        image_data  = resize_image(image, (self.input_shape[1], self.input_shape[0]), self.letterbox_image)\n",
    "        image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(image_data, dtype='float32')), (2, 0, 1)), 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            images = torch.from_numpy(image_data)\n",
    "            if self.cuda:\n",
    "                images = images.cuda()\n",
    "            outputs = self.net(images)\n",
    "            outputs = self.bbox_util.decode_box(outputs)\n",
    "            results = self.bbox_util.non_max_suppression(torch.cat(outputs, 1), self.num_classes, self.input_shape, \n",
    "                        image_shape, self.letterbox_image, conf_thres = self.confidence, nms_thres = self.nms_iou)\n",
    "                                                    \n",
    "            if results[0] is None: \n",
    "                return \n",
    "\n",
    "            top_label   = np.array(results[0][:, 6], dtype = 'int32')\n",
    "            top_conf    = results[0][:, 4] * results[0][:, 5]\n",
    "            top_boxes   = results[0][:, :4]\n",
    "\n",
    "        top_100     = np.argsort(top_conf)[::-1][:self.max_boxes]\n",
    "        top_boxes   = top_boxes[top_100]\n",
    "        top_conf    = top_conf[top_100]\n",
    "        top_label   = top_label[top_100]\n",
    "\n",
    "        for i, c in list(enumerate(top_label)):\n",
    "            predicted_class = self.class_names[int(c)]\n",
    "            box             = top_boxes[i]\n",
    "            score           = str(top_conf[i])\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            if predicted_class not in class_names:\n",
    "                continue\n",
    "\n",
    "            f.write(\"%s %s %s %s %s %s\\n\" % (predicted_class, score[:6], str(int(left)), str(int(top)), str(int(right)),str(int(bottom))))\n",
    "\n",
    "        f.close()\n",
    "        return \n",
    "    \n",
    "    def on_epoch_end(self, epoch, model_eval):\n",
    "        if epoch % self.period == 0 and self.eval_flag:\n",
    "            self.net = model_eval\n",
    "            if not os.path.exists(self.map_out_path):\n",
    "                os.makedirs(self.map_out_path)\n",
    "            if not os.path.exists(os.path.join(self.map_out_path, \"ground-truth\")):\n",
    "                os.makedirs(os.path.join(self.map_out_path, \"ground-truth\"))\n",
    "            if not os.path.exists(os.path.join(self.map_out_path, \"detection-results\")):\n",
    "                os.makedirs(os.path.join(self.map_out_path, \"detection-results\"))\n",
    "            print(\"Get map.\")\n",
    "            for annotation_line in tqdm(self.val_lines):\n",
    "                line        = annotation_line.split()\n",
    "                image_id    = os.path.basename(line[0]).split('.')[0]\n",
    "                #------------------------------#\n",
    "                # Read the image and convert it to an RGB image.\n",
    "                #------------------------------#\n",
    "                image       = Image.open(line[0])\n",
    "                #------------------------------#\n",
    "                # Get the predicted bounding boxes.\n",
    "                #------------------------------#\n",
    "                gt_boxes    = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
    "                #------------------------------#\n",
    "                # Get the prediction TXT file.\n",
    "                #------------------------------#\n",
    "                self.get_map_txt(image_id, image, self.class_names, self.map_out_path)\n",
    "                \n",
    "                #------------------------------#\n",
    "                # Get the ground truth TXT file.\n",
    "                #------------------------------#\n",
    "                with open(os.path.join(self.map_out_path, \"ground-truth/\"+image_id+\".txt\"), \"w\") as new_f:\n",
    "                    for box in gt_boxes:\n",
    "                        left, top, right, bottom, obj = box\n",
    "                        obj_name = self.class_names[obj]\n",
    "                        new_f.write(\"%s %s %s %s %s\\n\" % (obj_name, left, top, right, bottom))\n",
    "                        \n",
    "            print(\"Calculate Map.\")\n",
    "            try:\n",
    "                temp_map = get_coco_map(class_names = self.class_names, path = self.map_out_path)[1]\n",
    "            except:\n",
    "                temp_map = get_map(self.MINOVERLAP, False, path = self.map_out_path)\n",
    "            self.maps.append(temp_map)\n",
    "            self.epoches.append(epoch)\n",
    "\n",
    "            with open(os.path.join(self.log_dir, \"epoch_map.txt\"), 'a') as f:\n",
    "                f.write(str(temp_map))\n",
    "                f.write(\"\\n\")\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.plot(self.epoches, self.maps, 'red', linewidth = 2, label='train map')\n",
    "\n",
    "            plt.grid(True)\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Map %s'%str(self.MINOVERLAP))\n",
    "            plt.title('A Map Curve')\n",
    "            plt.legend(loc=\"upper right\")\n",
    "\n",
    "            plt.savefig(os.path.join(self.log_dir, \"epoch_map.png\"))\n",
    "            plt.cla()\n",
    "            plt.close(\"all\")\n",
    "\n",
    "            print(\"Get map done.\")\n",
    "            shutil.rmtree(self.map_out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
